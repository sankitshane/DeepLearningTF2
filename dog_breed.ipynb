{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dog_breed.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyND0DHTj7Fr9JaEEDOnl4Bw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sankitshane/DeepLearningTF2/blob/master/dog_breed.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKpx0XPbZOip",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "de03d31c-ebb0-4160-f6bb-f3090fcb70e0"
      },
      "source": [
        "from keras import initializers, layers\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import (\n",
        "    Dropout,\n",
        "    Input,\n",
        "    AveragePooling2D,\n",
        "    GlobalAveragePooling2D,\n",
        "    MaxPool2D\n",
        ")\n",
        "from keras.layers.convolutional import (\n",
        "    Conv2D,\n",
        "    MaxPooling2D,\n",
        "    ZeroPadding2D\n",
        ")\n",
        "from keras.layers.core import (\n",
        "    Activation,\n",
        "    Flatten,\n",
        "    Dense\n",
        ")\n",
        "from keras.layers.merge import (\n",
        "    concatenate,\n",
        "    add\n",
        ")\n",
        "from keras import backend as K\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "from keras.layers.pooling import GlobalMaxPooling2D\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xdsn-1VugHk6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AlexNet:\n",
        "  @staticmethod\n",
        "  def build(height, width, channel, classes, activation='relu', weightsPath=None):\n",
        "    model = Sequential()\n",
        "    inputShape = (height, width, channel)\n",
        "\n",
        "    if K.image_data_format() == \"channel_first\":\n",
        "      inputShape = (channel, height, width)\n",
        "    \n",
        "    model.add(Conv2D(96, 11, input_shape=inputShape, strides=(4, 4), padding='valid'))\n",
        "    model.add(Activation(activation))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2), padding='valid'))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Conv2D(256, 11, strides=(1, 1), padding='valid'))\n",
        "    model.add(Activation(activation))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2), padding='valid'))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Conv2D(384, 3, strides=(1, 1), padding='valid'))\n",
        "    model.add(Activation(activation))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Conv2D(384, 3, strides=(1, 1), padding='valid'))\n",
        "    model.add(Activation(activation))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Conv2D(256, 11, strides=(1, 1), padding='valid'))\n",
        "    model.add(Activation(activation))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2), padding='valid'))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Flatten())\n",
        "\n",
        "    model.add(Dense(4096, input_shape=(244*244*3,)))\n",
        "    model.add(Activation(activation))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Dense(4096))\n",
        "    model.add(Activation(activation))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Dense(1000))\n",
        "    model.add(Activation(activation))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Dense(classes))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    if weightsPath is not None:\n",
        "      model.load_weights(weightsPath)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Mm5WxTcf_rd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def spiltFolder(path, ratio):\n",
        "  import os\n",
        "  import shutil\n",
        "  import random\n",
        "\n",
        "  mainDir = os.path.join(path, 'Main')\n",
        "  trainDir = os.path.join(path, 'Train')\n",
        "  testDir = os.path.join(path, 'Test')\n",
        "  valDir = os.path.join(path, 'Validation')\n",
        "\n",
        "  if os.path.isdir(trainDir):\n",
        "    shutil.rmtree(trainDir)\n",
        "  if os.path.isdir(testDir):\n",
        "    shutil.rmtree(testDir)\n",
        "  if os.path.isdir(valDir):\n",
        "    shutil.rmtree(valDir)\n",
        "  \n",
        "  if not os.path.isdir(mainDir):\n",
        "    return \"Please have the Main Directory Intact\"\n",
        "\n",
        "  shutil.copytree(mainDir, trainDir)\n",
        "  os.mkdir(testDir)\n",
        "  os.mkdir(valDir)\n",
        "\n",
        "  listofcat = os.listdir(trainDir)\n",
        "\n",
        "  for cat in listofcat:\n",
        "    os.mkdir(os.path.join(valDir, cat))\n",
        "    minilist = os.listdir(os.path.join(trainDir, cat))\n",
        "    minilist_set = int(len(minilist) * (ratio / 100)) * 2\n",
        "\n",
        "    minilist = random.sample(minilist, minilist_set)\n",
        "    random_set = random.sample(minilist, minilist_set//2)\n",
        "\n",
        "    test_minilist = {}\n",
        "\n",
        "    for img in random_set:\n",
        "      test_minilist[img] = True\n",
        "      shutil.move(os.path.join(trainDir, cat, img), os.path.join(testDir, img))\n",
        "    for img in minilist:\n",
        "      if img not in test_minilist:\n",
        "        shutil.move(os.path.join(trainDir, cat, img), os.path.join(valDir, cat, img))\n",
        "    \n",
        "  return \"Image Rearranged\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_cHRODmCXd7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMSLsQ3QZD-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6Kny8weoUZ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAcGSZPooVHI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7357e7af-33fe-4ce5-e9c1-ef9ed918ab47"
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/drive/My Drive/DLData/Train',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 9084 images belonging to 120 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFGC93XNowH9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    '/content/drive/My Drive/DLData/validation',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LAH4fvEo06X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=2000,\n",
        "    epochs=50,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=800)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}